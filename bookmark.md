eccv2016 tutorials: http://www.eccv2016.org/tutorials/
cvpr2016 tutorials: http://cvpr2016.thecvf.com/program/tutorials
Deep Learning workshop: http://www.idiap.ch/workshop/dltm/
OpenCV docs: https://www.docs.opencv.org/2.4.13/
SGD算法比较：https://blog.slinuxer.com/2016/09/sgd-comparison
net scope: http://ethereon.github.io/netscope/#/preset/googlenet
CS229: http://cs229.stanford.edu/syllabus.html
google blog: http://developers.googleblog.cn/2017/07/blog-post.html
data augmentation: https://github.com/ShaharKatz/Caffe-Data-Augmentation
CNNTricks: http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html
Mask RCNN: https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4
Focal loss: http://blog.csdn.net/u014380165/article/details/77019084
Focal loss: https://www.zhihu.com/question/63581984
cross entropy: https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/
deep learning roadmap: https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap
interview questions: https://github.com/MaximAbramchuck/awesome-interview-questions
visualizing: http://colah.github.io/posts/2014-10-Visualizing-MNIST/
transfer learning: http://ruder.io/transfer-learning/index.html
机器学习：https://www.zhihu.com/question/22221180
凸优化眼里的世界：https://zhuanlan.zhihu.com/p/19692149?utm_campaign=rss&utm_medium=rss&utm_source=rss&utm_content=title&columnSlug=prml-paper-reading
freemind: http://freemind.pluskid.org/misc/optimization-and-assumptions/
CS231: http://cs231n.stanford.edu/
convnet on imagenet: http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/
neural network zoo: http://www.asimovinstitute.org/neural-network-zoo/
bagging: http://www.cnblogs.com/zhizhan/p/4992311.html
